{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IndoDataWeek-NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPbhms0sSa6kv0LOJCcv9mG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arezaz/nlp-workshop/blob/master/IndoDataWeek_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TAi_alZvBCt"
      },
      "source": [
        "#**The Natural Language Processing Workshop**\n",
        "---\n",
        "#### Alireza Rezazadeh (rezaz003@umn.edu)\n",
        "Indo Data Week - November, 2020\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfOCTOo2zuw9"
      },
      "source": [
        "## **1. Word Representation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSh5jrN4u9uW"
      },
      "source": [
        "#### **Overview**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwWR33Nctr01"
      },
      "source": [
        "\n",
        "1. Word Representation:\n",
        "  * 1.1. Basic Approaches\n",
        "      * 1.1.1. One-Hot Encoding\n",
        "      * 1.1.2. Bag of Words\n",
        "      * 1.1.3. TF-IDF\n",
        "  * 1.2. Word Embedding\n",
        "      * 1.2.1. Word2Vec\n",
        "      * 1.2.2. GloVe\n",
        "      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7HhWYa2-9UM"
      },
      "source": [
        "#### **1.1. Basic Aproaches**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykVx_bhd2gas"
      },
      "source": [
        "*Vector space model* is an algebraic model of representing text as vecotrs of identifiers. All following approaches discussed here are one way or another based on the idea of vector space models. Basic idea:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/arezaz/nlp-workshop/master/contents/1.png\" alt=\"Drawing\" width=\"350\" />\n",
        "\n",
        "The most basic idea: assigning unique ID to each word in the vocabulary. This way, we can represent text as a multi-dimensional vector. Let's go over a few ways to implement this idea!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRiwPax0BSHC"
      },
      "source": [
        "##### **1.1.1. One-Hot Encoding**\n",
        "<img src=\"https://raw.githubusercontent.com/arezaz/nlp-workshop/master/contents/2.png\" alt=\"Drawing\" width=\"700\" />\n",
        "\n",
        "Let's try this!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQXHKNJkG0fC"
      },
      "source": [
        "VOCAB = {'yellow':0, 'apple':1, 'dog':2, 'cat':3, 'blue':4, 'black':5, 'sky':6}"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGOwFx55u49d"
      },
      "source": [
        "def onehot(text):\n",
        "  ### your code here ###\n",
        "   \n",
        "  return onehot_rep"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbIq3DFvIG_C"
      },
      "source": [
        "onehot('the sky is blue and the cat is black')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_J4UsEeIYrn"
      },
      "source": [
        "Why is this approach not so practical?\n",
        "  * High dimensionality of the representation.\n",
        "  * Sparsity leads to computational difficaulties.\n",
        "  * Does not capture semantic relation between words.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvXYti6hJjTo"
      },
      "source": [
        "##### **1.1.2. Bag of Words**\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/arezaz/nlp-workshop/master/contents/3.png\" alt=\"Drawing\" width=\"700\" />\n",
        "\n",
        "Let's try this!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrGhyOkuIKre"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "corpus = [ 'This is the first document and it is interesting.',\n",
        "           'This document is the second document and it is in English.',\n",
        "           'And this is the third one.',\n",
        "           'Is this the first document?']\n",
        "\n",
        "count_vect = CountVectorizer() # CountVectorizer(binary=True)\n",
        "### your code here ###\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZC4pPgN_UsR3"
      },
      "source": [
        "# Bag-of-words representation of a new documents\n",
        "NewDocument = \"dog and dog are friends\"\n",
        "temp = count_vect.transform([NewDocument])\n",
        "print(\"BoW of '\" + NewDocument + \"': \",temp.toarray())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVtSkBv6GBNv"
      },
      "source": [
        "A few advantages:\n",
        "  *   Straight-forward and easy to implement.\n",
        "  *   Captures semantic similarity for documents.\n",
        "  *   Encoding is fixed length for any document.\n",
        "\n",
        "Some drawbacks:\n",
        "  *   Vectors could become sparse for larger vocabulary.\n",
        "  *   Blind! cannot capture semantic similarity of words.\n",
        "  *   What if a new word is not in the vocabulary?\n",
        "  *   It's a bag! disregards words order information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9IDS6sCJ9Su"
      },
      "source": [
        "##### **1.1.3. TF-IDF**\n",
        " \n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/arezaz/nlp-workshop/master/contents/4.png\" alt=\"Drawing\" width=\"1400\" />\n",
        "\n",
        "Let's try this!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6oSeZKlB5tw"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "\n",
        "### your code here ###\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikqpvJ_sURfu"
      },
      "source": [
        "NewDocument = \"This English document is interesting\"\n",
        "temp = tfidf.transform([NewDocument])\n",
        "print(\"TF-IDF for '\"+NewDocument+\"' :\\n\", temp.toarray())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UXKWAKgW_-k"
      },
      "source": [
        "There are a few variations of TF-IDF formulations. Advantages of this approach are:\n",
        "*   Like bag-of-words, it captures semantic similarity for documents.\n",
        "*   Very commonly used (even today!).\n",
        "\n",
        "But, like any other approach, there are some drawbacks:\n",
        "*   Curse of dimensionality! feature vectors can become very high dimensional.\n",
        "*   Still doesn't capture semantic relation between words.\n",
        "*   Sparsity in feature vecotors.\n",
        "*   Does not handle out-of-vocabulary words.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VZBixsGKc_E"
      },
      "source": [
        "#### **1.2. Word Embeddings**\n",
        "\n",
        "Words that can be used interchangably often have a strong semantic relation. \n",
        "\n",
        "> The [*cat*, *dog*] is a [*domestic*, *wild*] species of [*small*, *large*] carnivorous mammal.  - *Wikipedia*\n",
        "\n",
        "Word embeddings represent words as real-valued vectors in a predifined vector space. In particular, word embeddings are from the class of dense distributed representation. Unlike sparse representations, such as one-hot encoding, distributed representations are learned based on the usage of words. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrFE_yPkWnJy"
      },
      "source": [
        "##### **1.2.1. Word2Vec**\n",
        " \n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/arezaz/nlp-workshop/master/contents/5.png\" alt=\"Drawing\" width=\"1700\" />\n",
        "\n",
        "Word embedding models are usually trained on huge datasets with large vocabulary size. Luckily we don't need to train neural networks from scratch Let's try a pre-trained model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJGp2genc6a7"
      },
      "source": [
        "from gensim.models import Word2Vec \n",
        "from gensim.test.utils import common_texts\n",
        "\n",
        "# Build a Word2Vec model on a costume dataset\n",
        "model = Word2Vec(common_texts, size=10, window=5, min_count=1, workers=4)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLeFbFbRLDnr"
      },
      "source": [
        "# Finding similar words\n",
        "### your code here ###\n",
        "\n",
        "# the representation for one of the words\n",
        "### your code here ###\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6HD6l3DMLi4"
      },
      "source": [
        "##### **1.2.2. GLoVe**\n",
        " \n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/arezaz/nlp-workshop/master/contents/6.png\" alt=\"Drawing\" width=\"1700\" />\n",
        "\n",
        "Let's try a pre-trained GLoVe model based on twitter data!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZLPvi6ULvhr"
      },
      "source": [
        "import gensim.downloader\n",
        "\n",
        "# loading GloVe model trained on tweets\n",
        "glove_model = gensim.downloader.load('glove-twitter-25')\n",
        "\n",
        "# Finding similar words\n",
        "### your code here ###\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FQKjGl-Up12"
      },
      "source": [
        "To measure similarity between two vectors we can use *cosine similarity* metric. It is defined to equal the cosine of the angle between them, which is also the same as the inner product of the same vectors normalized to both have length 1.\n",
        "\n",
        "<img src=\"https://www.oreilly.com/library/view/mastering-machine-learning/9781785283451/assets/d258ae34-f4f8-4143-b3c2-0cb10f2b82de.png\" alt=\"Drawing\" width=\"800\" />\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr5cp7YWNLRs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlcTq_l-V9Mt"
      },
      "source": [
        "from scipy import spatial\n",
        "\n",
        "# similarity function based on cosine similarity\n",
        "def similarity(w1,w2):\n",
        "  ### your code here ###\n",
        "  \n",
        "  return  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5c3rLTqWXDV"
      },
      "source": [
        "# compare the similarity of 'man', 'woman', and 'umbrella'!\n",
        "### your code here ###\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z569ldFWsdm"
      },
      "source": [
        "# compare the similarity of 'large', 'larger', and 'small', 'smaller'\n",
        "### your code here ###\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APm3BHWvZCxR"
      },
      "source": [
        "This is interesting. But wait! does data equally favor everyone? What if we want to somehow use a model trained on a large dataset of tweets to make a decision for the society? \n",
        "\n",
        "Let's take a look at how language can be unfair and biased! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7Y3-toPY0yy"
      },
      "source": [
        "# compare similarities between 'careers' and 'names'!\n",
        "### your code here ###\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYJGwtcTdnZH"
      },
      "source": [
        "We experimented with one of the common word embedding models and observed how based on biased data a machine learning model can be biased. Recently, the subject of AI fairness has been attracting more attention.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "105L3Kg7eujE"
      },
      "source": [
        "## **2. Language Models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aupwnnrvapFI"
      },
      "source": [
        "#### **Overview**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvZtzYhbapFJ"
      },
      "source": [
        "2. Language Models\n",
        "  * 2.1 Basic Models\n",
        "      * 2.1.1. Unigram/Bigram Models\n",
        "      * 2.1.2. N-grams Models\n",
        "  * 2.2 Recurrent Nerual Networks (RNN)\n",
        "      * 2.2.1. Basic RNN\n",
        "      * 2.2.2. Vanilla RNN\n",
        "      * 2.2.3. LSTM\n",
        "      * 2.2.4. Deep RNN\n",
        "\n",
        "* Hands-on: Building a Language Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmVnXg5U7rZv"
      },
      "source": [
        "#### **2.1. Basic Models**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NlrkdWm17WX"
      },
      "source": [
        "Language models, originally developed for speech recognition, are widely used in many NLP applications. Probabilistic language models compute the probability of a sentence or sequence of words. Specifically, language models can be developed to predict the likelihood of a given word, or a sequence of words, to follow a sequence of words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXjBHAR3Fxie"
      },
      "source": [
        "##### **2.1.1. Unigram/Bigram Models**\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/arezaz/nlp-workshop/master/contents/7.png\" alt=\"Drawing\" width=\"1700\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9mYKBHwF8sd"
      },
      "source": [
        "##### **2.1.2. N-gram Models**\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/arezaz/nlp-workshop/master/contents/8.png\" alt=\"Drawing\" width=\"1800\" />\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KoZRqAzbiLO"
      },
      "source": [
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "# function to extract n-grams of sentences\n",
        "def ngrams_gen(seq, n):\n",
        "  ### your code here ###\n",
        "\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKf2jsYZKf03"
      },
      "source": [
        "# generate n-grams!: n = 1, 2, 3, 4\n",
        "sentence = 'The whole is more than the sum of its parts' # -Aristotle\n",
        "\n",
        "### your code here ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQCMAJlBLvLj"
      },
      "source": [
        "In general, N-gram models are not sufficient models for language altough they are very useful. Language is essentially dependent on complicated long-distance histories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b3pSNeKLJBN"
      },
      "source": [
        "#### **2.2. Recurrent Neural Networks**\n",
        "\n",
        "As mentioned earlier, language is sequential at its essense. *Recurrent neural networks* (RNN) are specifically developed to capture a sequential process. In general, RNN is composed of units that keep a memory of preceeding history. This memory is temporal as the units keep updating at every timestep. RNN are very promising in many NLP applications.\n",
        "\n",
        "\n",
        "*images courtesy of cs230 - stanford, and colah.github.io*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7MAUACyMz2l"
      },
      "source": [
        "##### **2.2.1. Basic RNN**\n",
        "\n",
        "At each timestep $t$, the unit takes input $x^{<t>}$, outputs $y^{<t>}$, and pass a signal $a^{<t>}$ based on its computations to the next timestep $t+1$. This signal acts as a memory in the sequence.\n",
        "\n",
        "\n",
        "<img src=\"https://stanford.edu/~shervine/teaching/cs-230/illustrations/architecture-rnn-ltr.png?9ea4417fc145b9346a3e288801dbdfdc\" alt=\"Drawing\" width=\"600\" />\n",
        "\n",
        "Specifically, \n",
        "\n",
        "$a^{<t>}=g_a(W_a [a^{<t-1>}, x^{<t>}]+b_a)$\n",
        "\n",
        "$\\hat{y}^{<t>}=g_y(W_y a^{<t>}+b_y)$\n",
        "\n",
        "The loss function is defined as: $L(\\hat{y}-y) = \\sum_{t=1}^{T}L(\\hat{y}^{<t>}-y^{<t>}) $. The RNN network is trained by *backpropagation through time*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAMamkSbY6Ja"
      },
      "source": [
        "Type | Schematic | Application\n",
        " --- |    ---    |     ---\n",
        "one-to-one | <img src=\"https://stanford.edu/~shervine/teaching/cs-230/illustrations/rnn-one-to-one-ltr.png?9c8e3b04d222d178d6bee4506cc3f779\" alt=\"Drawing\" width=\"400\" /> | a basic nerual network \n",
        "one-to-many | <img src=\"https://stanford.edu/~shervine/teaching/cs-230/illustrations/rnn-one-to-many-ltr.png?d246c2f0d1e0f43a21a8bd95f579cb3b\" alt=\"Drawing\" width=\"400\" /> | music generation\n",
        "many-to-one | <img src=\"https://stanford.edu/~shervine/teaching/cs-230/illustrations/rnn-many-to-one-ltr.png?c8a442b3ea9f4cb81f929c089b910c9d\" alt=\"Drawing\" width=\"400\" /> | sentiment classification\n",
        "many-to-many | <img src=\"https://stanford.edu/~shervine/teaching/cs-230/illustrations/rnn-many-to-many-same-ltr.png?2790431b32050b34b80011afead1f232\" alt=\"Drawing\" width=\"400\" /> | named-entity recognition (NER)\n",
        "many-to-many | <img src=\"https://stanford.edu/~shervine/teaching/cs-230/illustrations/rnn-many-to-many-different-ltr.png?8ca8bafd1eeac4e8c961d9293858407b\" alt=\"Drawing\" width=\"400\" /> | machine translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdaLEvYNqrLm"
      },
      "source": [
        "##### **2.2.2. Vanilla RNN**\n",
        "\n",
        "Vanilla RNN is a basic RNN unit. The non-linearity function is set to $tanh$ and can be described as:\n",
        "\n",
        "$a^{<t>}=tanh(W_a[a^{<t-1>}, x^{<t>}]+b_a)$\n",
        "\n",
        "\n",
        "\n",
        "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-SimpleRNN.png\" alt=\"Drawing\" width=\"600\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbmjA454tGkS"
      },
      "source": [
        "##### **2.2.3. LSTM**\n",
        "\n",
        "LSTM (long short-term memory) network introduced back in 1990s are extremely promising in a wide variety of sequential modelings. They are formulated to allow for learning lags of unknown duration between relevant events in a sequential data. A major feature of LSTMs is their capability in experssing the notion of forgetting.\n",
        "\n",
        "There are many variations of LSTMs. In general, an LSTM cell has three main components, also called *gates*: input gate, output gate, and forget gate. On top of that, each cell has a *state* associated with it.\n",
        "\n",
        "\n",
        "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png\" alt=\"Drawing\" width=\"600\" />\n",
        "\n",
        "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM2-notation.png\" alt=\"Drawing\" width=\"500\" />\n",
        "\n",
        "\n",
        "So, what is the main idea?\n",
        "\n",
        "The cell state runs through all timesteps and the cell can add or remove information to the state signal. The three gates allows the cell to arbitrarily let information through. Gates are composed of sigmoid function to determine how much of each component let through. \n",
        "\n",
        "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-C-line.png\" alt=\"Drawing\" width=\"700\" />\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8AoBAG1y2b4"
      },
      "source": [
        "Let's briefly walk through an LSTM cell:\n",
        "\n",
        "*1) Decide what to forget:* look at the previous timestep hidden state $h_{t-1}$ and the input at this timestep $x_t$ and through a sigmoid layer determine how much to forget *(forget gate)*: \n",
        "\n",
        "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-f.png\" alt=\"Drawing\" width=\"700\" />\n",
        "\n",
        "*2) Decide what to remember:* look at the previous timestep hidden state $h_{t-1}$ and the input at this timestep $x_t$. First, decide which values to update through a sigmoid layer *(input gate)*. Then, compute the candidate values for the updates: \n",
        "\n",
        "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-i.png\" alt=\"Drawing\" width=\"700\" />\n",
        "\n",
        "*3) Update cell states:* now that we know what to remember and what to forget we can impose them to the cell state signal: \n",
        "\n",
        "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-C.png\" alt=\"Drawing\" width=\"700\" />\n",
        "\n",
        "*4) Come up with an output:* look at the previous timestep hidden state $h_{t-1}$ and through a sigmoid layer decide what parts of this signal to update and output (*output gate*). Then, combine this signal with the candidate update values and compute the hidden state at this timestep $h_{1}$: \n",
        "\n",
        "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-focus-o.png\" alt=\"Drawing\" width=\"700\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI0y1qHT9JbR"
      },
      "source": [
        "As mentioned before, LSTMs are great and promising in general but we should also be aware of some of their drawbacks:\n",
        "\n",
        "* LSTMs are developed to solve the problem of vanishing gradients in the process of backpropagation. However, they also suffer from vanishing gradient problem to some extent.\n",
        "* The cell function is quite complex and this can exacerbate the issue of vanishing gradients.\n",
        "* Computationally expensive to train up to a decent performance level.\n",
        "* Cannot remember history of sequence for relatively longer timesteps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrMPWDe6-c6n"
      },
      "source": [
        "##### **2.2.4. Deep RNN**\n",
        "\n",
        "How do we make an RNN deep? just stack them up and build layers on top of each other!\n",
        "\n",
        "<img src=\"https://stanford.edu/~shervine/teaching/cs-230/illustrations/deep-rnn-ltr.png?f57da6de44ddd4709ad3b696cac6a912\" alt=\"Drawing\" width=\"400\" />\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLpsws9nAL5E"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isu0GoCnAPBs"
      },
      "source": [
        "## 3. Hands-on: Working with Transformers\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgTBHHqelZi-"
      },
      "source": [
        "### So, what are the Transformers really?\n",
        "\n",
        "Transformer in natural language processing refers to state of the art sequence-to-sequence language models. The backbone of transformers is *attention mechanism* to handle long distance dependencies. \n",
        "\n",
        "Attention mechanism basically weights different positions of a single sequence in order to compute a representation of the sequence. Here's how it looks:\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/700/1*wa4zt-LcMWRIYLfiHfBKvA.png\" alt=\"Drawing\" width=\"450\" />\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SK4Pnym4vrGG"
      },
      "source": [
        "### 3.1. GPT-2\n",
        "Generative  Pre-trained Transformers (GPT) are developed by OpenAI. GPT-2 is released in 4 different variations based on their size (small, medium, large, and XL). GPT-2 is a very large model with 1.5 billion parameters. The pre-trained models contain information from 8 million web pages from. GPT-2 is an unsupervised language model announced in 2019. Building blocks of GPT-2 is:\n",
        "\n",
        "<img src=\"https://camo.githubusercontent.com/795bd8868fdeb49b7ca48a935e806b56169a172b/68747470733a2f2f692e696d6775722e636f6d2f305853535842642e706e67\" alt=\"Drawing\" width=\"180\" />\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9-3C7TEy8vm"
      },
      "source": [
        "#### 3.1.1. Next Word Generation Using GPT-2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3ZkEp2NCFBj"
      },
      "source": [
        "!pip install pytorch-transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Uid3k0Z0FBb"
      },
      "source": [
        "# importing GPT2 library\n",
        "import torch\n",
        "from pytorch_transformers import GPT2Tokenizer, GPT2LMHeadModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oFKm95w0FDV"
      },
      "source": [
        "# creating an instance of GPT-2 tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lhHdQlU0g-4"
      },
      "source": [
        "# loading a pre-trained GPT-2 model with multi-head attention mechanism\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "model.eval()\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Plo02bnR0FHq"
      },
      "source": [
        "# let's predict the next word in this sequence\n",
        "text = \"artificial inteligence aims to predict the\"\n",
        "indexed_tokens = tokenizer.encode(text)\n",
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "print(f'tokens are: {indexed_tokens}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FoojtWG1Nyh"
      },
      "source": [
        "# Predicting the next word in the sequence\n",
        "with torch.no_grad():\n",
        "    outputs = model(tokens_tensor)\n",
        "    predictions = outputs[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7VRW-q01PDg"
      },
      "source": [
        "predicted_index = torch.argmax(predictions[0, -1, :]).item()\n",
        "predicted_text = tokenizer.decode(indexed_tokens + [predicted_index])\n",
        "predicted_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACKqs1Gb18k7"
      },
      "source": [
        "#### 3.1.2. Next Sentences Generation Using GPT-2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw6MNchq1PFw"
      },
      "source": [
        "start = 'Intelligence is most often studied in humans but has also been observed in both'\n",
        "indexed_tokens = tokenizer.encode(start)\n",
        "\n",
        "for i in range(150):\n",
        "  tokens_tensor = torch.tensor([indexed_tokens])\n",
        "  with torch.no_grad():\n",
        "    outputs = model(tokens_tensor)\n",
        "    predictions = outputs[0]\n",
        "    predicted_index = torch.argmax(predictions[0, -1, :]).item()\n",
        "    indexed_tokens = indexed_tokens + [predicted_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_lB3EDg1PIR"
      },
      "source": [
        "predicted_text = tokenizer.decode(indexed_tokens + [predicted_index])\n",
        "print(predicted_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQZlGf5p3sVt"
      },
      "source": [
        "---\n",
        "## Relevant Materials\n",
        "* Vajjala, Majumder, Gupta, Surana - [Practical Natural Language Processing: A Comprehensive Guide to Building Real-World NLP Systems](https://www.amazon.com/Practical-Natural-Language-Processing-Pragmatic/dp/1492054054)\n",
        "* [Sequence Models](https://www.coursera.org/learn/nlp-sequence-models) by deeplearning.ai\n",
        "* [Stanford's CS230](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks) course materials\n",
        "* Christopher Olah's [blog](https://colah.github.io/)\n"
      ]
    }
  ]
}
